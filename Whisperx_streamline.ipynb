{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinyiLi9/databrick-copy/blob/main/Whisperx_streamline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the notebook from here"
      ],
      "metadata": {
        "id": "rVAMtoR6WSZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BqpcbS1u9lr",
        "outputId": "29addbb7-36b1-4180-f5f2-b49d4dec74fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def starter():\n",
        "  \"\"\"\n",
        "  Starting the environment\n",
        "  \"\"\"\n",
        "  # 1. import modules\n",
        "  os.system(\"pip install git+https://github.com/m-bain/whisperx.git\")\n",
        "  os.system(\"pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117\")\n",
        "  os.system(\"pip install openai\")\n",
        "starter()"
      ],
      "metadata": {
        "id": "ane6Su9RPsjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to get in a video and transform that into audio form."
      ],
      "metadata": {
        "id": "L0YEUSitTuQS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[A quick guide on ffmpeg](https://opensource.com/article/17/6/ffmpeg-convert-media-file-formats)"
      ],
      "metadata": {
        "id": "s1sbNBd9HV6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "@anvil.server.callable\n",
        "def v2a(file_path):\n",
        "  \"\"\"\n",
        "  Get the audio from the video file\n",
        "\n",
        "  Note that we do require each video to be under 10 min!!\n",
        "\n",
        "  \"\"\"\n",
        "  current_working_directory = os.getcwd()\n",
        "  save_path = current_working_directory + \"/audio-only.mp3\"\n",
        "  print(\"Saving audio in \" + save_path)\n",
        "  try:\n",
        "    os.system(\"ffmpeg -i {} -vn {}\".format(file_path, save_path))\n",
        "  except KeyError:\n",
        "      print(\"error\")\n",
        "  return save_path"
      ],
      "metadata": {
        "id": "ELydteThI7rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = v2a(\"/content/gdrive/MyDrive/MS_example1/MS_sample1.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3nebQFWJl4O",
        "outputId": "919ee129-40ef-4590-873d-b4833c785f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving audio in /content/audio-only.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-cJuhH5dXjsS",
        "outputId": "7dce0278-013e-438a-e41b-c06176704cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/audio-only.mp3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "def transcribe(file):\n",
        "  \"\"\"\n",
        "  ONLY RUN THIS ONE IF NO SPEAKER IDENTIFICATION IS NEEDED\n",
        "\n",
        "  file: the path to the video path\n",
        "  \"\"\"\n",
        "  save_path = os.getcwd()\n",
        "  print(\"Saving results in \" + save_path)\n",
        "  os.system(\"whisperx {} --model large-v2 --language en --output_dir {} --align_model WAV2VEC2_ASR_LARGE_LV60K_960H --batch_size 4\".format(file, save_path))"
      ],
      "metadata": {
        "id": "m3PCKAbFQqSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjqcHDNUR_2L",
        "outputId": "b073521b-630e-4110-e616-55ef9b1337ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the diarization version (having speakers there)\n",
        "\n",
        "MUST get the tokens from https://huggingface.co/Xinyi99"
      ],
      "metadata": {
        "id": "2YWbeFWCDzoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@anvil.server.callable\n",
        "def speaker_transcribe(file_path):\n",
        "  \"\"\"\n",
        "  Transcription with speaker identification\n",
        "\n",
        "  Parameters:\n",
        "  --------------------------------------\n",
        "  file_path: str, the path of the audio\n",
        "\n",
        "  Returns:\n",
        "  ----------------------------------\n",
        "  save_path: path where the transcriptions are saved - (.json, .srt, .tsv, .txt, .vtt)\n",
        "\n",
        "  GPU warning:\n",
        "  ------------------------------------\n",
        "  Notice this cell must be run with GPU backend\n",
        "  \"\"\"\n",
        "  current_working_directory = os.getcwd()\n",
        "  save_path = current_working_directory + \"/speaker_identification/\"\n",
        "  print(\"Saving results in \" + save_path)\n",
        "  os.system('whisperx {} --model large-v2 --language en --output_dir {} --diarize --hf_token \"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\"'.format(file_path,save_path))\n",
        "  return save_path"
      ],
      "metadata": {
        "id": "FCdpKmzdd4vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe_path = speaker_transcribe(audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPh0FVrKeh79",
        "outputId": "84b3573c-550d-4674-ed7b-9adadb3fa328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving results in /content/speaker_identification/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def subtitle2video(video_path, transcribe_path):\n",
        "  \"\"\"\n",
        "  Generate subtitles and put them back to the video\n",
        "\n",
        "  \"\"\"\n",
        "  subtitle_path = transcribe_path + \"audio-only.vtt\"\n",
        "  os.system(\"ffmpeg -i {} -vf subtitles={} new_video_out.mp4\".format(video_path, subtitle_path))"
      ],
      "metadata": {
        "id": "BMGv61OYlrL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subtitle2video(\"/content/gdrive/MyDrive/MS_example1/MS_sample1.mp4\", transcribe_path)"
      ],
      "metadata": {
        "id": "vVmi2J4Zma_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "API_KEY = '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' # this part should keep confidential\n",
        "openai.api_key = API_KEY\n",
        "\n",
        "def text2sum(para):\n",
        "    summary = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt= para + \"\\n\\ntl;dr\",        # for text summarization\n",
        "        temperature=0.65,     # gives a relative creative response\n",
        "        max_tokens=200,\n",
        "        top_p=1.0,                # default value\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=1.0       # increasing the model's likelihood to talk about new topics\n",
        "    )\n",
        "    return summary['choices'][0]['text']\n",
        "\n",
        "def summary(txt_file, n=3):\n",
        "  \"\"\"\n",
        "  Use the txt file of the subtitles to generate summary\n",
        "\n",
        "  Parameters:\n",
        "  ------------------------------\n",
        "  txt_file: str\n",
        "  n: the number of summaries we want to see\n",
        "\n",
        "  Returns:\n",
        "  ------------------------------\n",
        "  return: result, a list of summaries generated\n",
        "  \"\"\"\n",
        "  media_file = open(txt_file, 'r')\n",
        "  # remove escape sequence '\\n' in the text\n",
        "  para = media_file.read().replace(\"\\n\", \" \")\n",
        "  result = []\n",
        "  for i in range(n):\n",
        "    summary = text2sum(para)\n",
        "    result.append(summary)\n",
        "  return result"
      ],
      "metadata": {
        "id": "4aDWsl8goug_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(\"/content/speaker_identification/audio-only.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfWICn8Yw4mg",
        "outputId": "9b9b48f9-6bf4-4913-f467-0dbba0be74d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\": The man's car was stolen and he made a report with the sheriff. When he got it back, the front license plate was missing. He was asked for his ID and registration but they found that the plate was listed as possibly stolen. He was advised to get it checked out to make sure no one had taken his plate and put it on another car.\",\n",
              " \" - The police ran the license plate of a car to make sure it wasn't stolen. The plate came back as possibly stolen, but the police couldn't tell if it was put on another car or not. They ran the registration and found out that it belonged to the original owner, but the DMV had not updated their address yet.\",\n",
              " ': The police pulled over the car and checked the plate to verify that it was not stolen. They found that it was listed as a possible stolen plate, but could not tell if it had been put on another car. They apologized for any inconvenience caused.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "presence_penalty\n",
        "Defaults to 0\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "frequency_penalty\n",
        "Defaults to 0\n",
        "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CxMa9lEg4mS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get bookmarks generated by ChatGPT"
      ],
      "metadata": {
        "id": "eNZYUDzpzIOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bookmark(file_path, n=5):\n",
        "  \"\"\"\n",
        "  Generate bookmarks\n",
        "\n",
        "  Parameters:\n",
        "  -----------------------------\n",
        "  file_path: vtt file\n",
        "\n",
        "  Returns:\n",
        "  -----------------------------\n",
        "  response: generated bookmarks with timestamps\n",
        "  \"\"\"\n",
        "  media_file = open(file_path, 'r')\n",
        "  timed_para = media_file.read().replace(\"\\n\", \" \")\n",
        "  completion = openai.Completion.create(\n",
        "    engine= \"text-davinci-003\",\n",
        "    prompt= timed_para + \" please generate {} bookmarks that highlight activities, and describe each of them using simple words ignoring speakers\".format(n),\n",
        "    max_tokens=512,\n",
        "    # n=1,\n",
        "    stop=None,\n",
        "    temperature=0.7,\n",
        "  )\n",
        "  response = completion.choices[0].text\n",
        "  return response"
      ],
      "metadata": {
        "id": "xz4gnolC3VbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = bookmark(\"/content/speaker_identification/audio-only.vtt\")"
      ],
      "metadata": {
        "id": "dNh3N7Je4dBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvZ0piQM5Acu",
        "outputId": "88ecd935-ca7e-46a8-c114-df06a3da7908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Bookmark 1: 3431 Code In - 1:04 - 1:12\n",
            "Description: Code is entered.\n",
            "\n",
            "Bookmark 2: Possible Stolen Plate - 9:30 - 9:52\n",
            "Description: Plate possibly stolen is checked.\n",
            "\n",
            "Bookmark 3: Registration Check - 4:31 - 4:45\n",
            "Description: Registration is checked.\n",
            "\n",
            "Bookmark 4: Vehicle Description - 7:54 - 8:13\n",
            "Description: Vehicle description is discussed.\n",
            "\n",
            "Bookmark 5: Report Made - 9:13 - 9:22\n",
            "Description: Report is made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrap up"
      ],
      "metadata": {
        "id": "sJVC64e27Dlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  starter()\n",
        "  # replace the path with your VIDEO path\n",
        "  audio_path = v2a(\"/content/gdrive/MyDrive/MS_example1/MS_sample1.mp4\")\n",
        "  transcribe_path = speaker_transcribe(audio_path)\n",
        "  # replace the path with your VIDEO path\n",
        "  subtitle2video(\"/content/gdrive/MyDrive/MS_example1/MS_sample1.mp4\", transcribe_path)\n",
        "  # replace the path with your AUDIO-ONLY.TXT file\n",
        "  s = summary(\"/speaker_identification/audio-only.txt\")\n",
        "  print(s)\n",
        "  # replace the path with your AUDIO-ONLY.VTT file\n",
        "  result = bookmark(\"/content/speaker_identification/audio-only.vtt\")\n",
        "  print(result)"
      ],
      "metadata": {
        "id": "_3ks-Zfe7EcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sUE2jAfbnS5q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}